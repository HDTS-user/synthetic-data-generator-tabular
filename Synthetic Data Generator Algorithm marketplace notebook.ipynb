{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Synthetic data generation Algorithm Model Package from AWS Marketplace \n",
    "\n",
    "Description !!\n",
    "\n",
    "This sample notebook shows you how to deploy Synthetic data generation Algorithm using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Synthetic data generation Algorithm. If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Output Result](#D.-Output-Result)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform batch inference](#3.-Perform-batch-inference) \n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the algorithm listing page **Synthetic data generation Algorithm**\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Usage Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deployed solution has these **2 steps**: Training the algorithm and Testing\n",
    "\n",
    "<li>: The system trains on user provided real dataset in csv file.\n",
    "<li>: The input training dataset with maximum 1000 rows.\n",
    "<li>: The machine learning model is trained in the training step and once the model is generated, it can be used to generate synthetic data.\n",
    "<li>: The testing API takes json input with number of samples and output is a csv file.\n",
    "<li>: In the usage instruction notebook, the detailed steps are mentioned to train the algorithm, generate the output and interpret the output.\n",
    "\n",
    "#### Input:\n",
    "** Following are the mandatory inputs for both the APIs:**\n",
    "• Supported content type for Training API: `text/csv`\n",
    "• Supported content type for Testing API: ` application/json`\n",
    "• The training dataset (csv file) can have maximum 1000 rows ??\n",
    "\n",
    "#### Output:\n",
    "•  Content types: ` text/csv`\n",
    "#### Invoking endpoint\n",
    "##### AWS CLI Command\n",
    "If you are using real time inferencing, please create the endpoint first and then use the  following command to invoke it:\n",
    "``` bash \n",
    "aws sagemaker-runtime invoke-endpoint --endpoint-name \"endpoint-name\" --body fileb://$file_name --content-type application/json --accept application/output.csv\n",
    "```\n",
    "Substitute the following parameters:\n",
    "* `\"endpoint-name\"` - name of the inference endpoint where the model is deployed.\n",
    "* `file_name` - Input csv file name\n",
    "* `application/json` - type of the given input file.\n",
    "* `output.csv` - filename where the inference results are written to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import base64 \n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-822940408628'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket=sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S3 prefixes\n",
    "common_prefix = \"hdts-sagemaker-testing\"\n",
    "training_input_prefix = common_prefix + \"/training-input-data\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING_WORKDIR = \"data/training\"\n",
    "\n",
    "#TRAINING_DATA = TRAINING_WORKDIR + \"/train.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING_WORKDIR = \"data/training\"\n",
    "\n",
    "# training input location\n",
    "training_input = sagemaker_session.upload_data(TRAINING_WORKDIR, key_prefix=training_input_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from sagemaker.algorithm import AlgorithmEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algorithm ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algorithm_arn ='arn:aws:sagemaker:us-east-1:822940408628:algorithm/synth-data-generation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "algo = AlgorithmEstimator(\n",
    "    algorithm_arn=algorithm_arn,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.2xlarge',\n",
    "    base_job_name='synth-train-marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: synth-train-marketplace-2023-11-08-10-36-24-837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now run the training job using algorithm arn arn:aws:sagemaker:us-east-1:822940408628:algorithm/synth-data-generation in region us-east-1\n",
      "2023-11-08 10:36:25 Starting - Starting the training job...\n",
      "2023-11-08 10:36:41 Starting - Preparing the instances for training......\n",
      "2023-11-08 10:37:49 Downloading - Downloading input data...\n",
      "2023-11-08 10:38:14 Training - Downloading the training image.....................\n",
      "2023-11-08 10:41:35 Training - Training image download completed. Training in progress..\u001b[34mtraining started\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mEpoch 1, Loss G:  2.1033,Loss D: -0.0195\u001b[0m\n",
      "\u001b[34mEpoch 2, Loss G:  2.1088,Loss D: -0.1069\u001b[0m\n",
      "\u001b[34mEpoch 3, Loss G:  2.1661,Loss D: -0.1579\u001b[0m\n",
      "\u001b[34mEpoch 4, Loss G:  2.1705,Loss D: -0.2282\u001b[0m\n",
      "\u001b[34mEpoch 5, Loss G:  2.1515,Loss D: -0.3554\u001b[0m\n",
      "\u001b[34mEpoch 6, Loss G:  2.1723,Loss D: -0.4758\u001b[0m\n",
      "\u001b[34mEpoch 7, Loss G:  2.1143,Loss D: -0.5485\u001b[0m\n",
      "\u001b[34mEpoch 8, Loss G:  2.0712,Loss D: -0.7154\u001b[0m\n",
      "\u001b[34mEpoch 9, Loss G:  2.0739,Loss D: -0.7998\u001b[0m\n",
      "\u001b[34mEpoch 10, Loss G:  2.0166,Loss D: -0.7739\u001b[0m\n",
      "\u001b[34mEpoch 11, Loss G:  1.9179,Loss D: -0.8077\u001b[0m\n",
      "\u001b[34mEpoch 12, Loss G:  1.8107,Loss D: -0.6498\u001b[0m\n",
      "\u001b[34mEpoch 13, Loss G:  1.7950,Loss D: -0.6842\u001b[0m\n",
      "\u001b[34mEpoch 14, Loss G:  1.7791,Loss D: -0.7123\u001b[0m\n",
      "\u001b[34mEpoch 15, Loss G:  1.6510,Loss D: -0.6874\u001b[0m\n",
      "\u001b[34mEpoch 16, Loss G:  1.7007,Loss D: -0.5345\u001b[0m\n",
      "\u001b[34mEpoch 17, Loss G:  1.7667,Loss D: -0.3938\u001b[0m\n",
      "\u001b[34mEpoch 18, Loss G:  1.6173,Loss D: -0.5193\u001b[0m\n",
      "\u001b[34mEpoch 19, Loss G:  1.6653,Loss D: -0.3146\u001b[0m\n",
      "\u001b[34mEpoch 20, Loss G:  1.6875,Loss D: -0.3298\u001b[0m\n",
      "\u001b[34mEpoch 21, Loss G:  1.7585,Loss D: -0.4289\u001b[0m\n",
      "\u001b[34mEpoch 22, Loss G:  1.6830,Loss D: -0.3683\u001b[0m\n",
      "\u001b[34mEpoch 23, Loss G:  1.8347,Loss D: -0.3647\u001b[0m\n",
      "\u001b[34mEpoch 24, Loss G:  1.8462,Loss D: -0.3559\u001b[0m\n",
      "\u001b[34mEpoch 25, Loss G:  1.8346,Loss D: -0.2355\u001b[0m\n",
      "\u001b[34mEpoch 26, Loss G:  1.7561,Loss D: -0.3407\u001b[0m\n",
      "\u001b[34mEpoch 27, Loss G:  1.7832,Loss D: -0.1984\u001b[0m\n",
      "\u001b[34mEpoch 28, Loss G:  1.6398,Loss D: -0.1172\u001b[0m\n",
      "\u001b[34mEpoch 29, Loss G:  1.5740,Loss D: -0.0264\u001b[0m\n",
      "\u001b[34mEpoch 30, Loss G:  1.5333,Loss D:  0.0575\u001b[0m\n",
      "\u001b[34mEpoch 31, Loss G:  1.4511,Loss D:  0.1922\u001b[0m\n",
      "\u001b[34mEpoch 32, Loss G:  1.4904,Loss D:  0.0927\u001b[0m\n",
      "\u001b[34mEpoch 33, Loss G:  1.4781,Loss D:  0.1072\u001b[0m\n",
      "\u001b[34mEpoch 34, Loss G:  1.3891,Loss D:  0.1122\u001b[0m\n",
      "\u001b[34mEpoch 35, Loss G:  1.3255,Loss D:  0.1046\u001b[0m\n",
      "\u001b[34mEpoch 36, Loss G:  1.4173,Loss D: -0.0788\u001b[0m\n",
      "\u001b[34mEpoch 37, Loss G:  1.4609,Loss D: -0.0134\u001b[0m\n",
      "\u001b[34mEpoch 38, Loss G:  1.6068,Loss D: -0.0303\u001b[0m\n",
      "\u001b[34mEpoch 39, Loss G:  1.4786,Loss D: -0.0185\u001b[0m\n",
      "\u001b[34mEpoch 40, Loss G:  1.4542,Loss D: -0.1790\u001b[0m\n",
      "\u001b[34mEpoch 41, Loss G:  1.4334,Loss D: -0.1195\u001b[0m\n",
      "\u001b[34mEpoch 42, Loss G:  1.2509,Loss D: -0.0917\u001b[0m\n",
      "\u001b[34mEpoch 43, Loss G:  1.2275,Loss D:  0.1479\u001b[0m\n",
      "\u001b[34mEpoch 44, Loss G:  1.3985,Loss D:  0.1664\u001b[0m\n",
      "\u001b[34mEpoch 45, Loss G:  1.3047,Loss D:  0.1620\u001b[0m\n",
      "\u001b[34mEpoch 46, Loss G:  1.1306,Loss D:  0.2373\u001b[0m\n",
      "\u001b[34mEpoch 47, Loss G:  1.2043,Loss D:  0.1972\u001b[0m\n",
      "\u001b[34mEpoch 48, Loss G:  0.9330,Loss D:  0.2529\u001b[0m\n",
      "\u001b[34mEpoch 49, Loss G:  1.3464,Loss D:  0.1249\u001b[0m\n",
      "\u001b[34mEpoch 50, Loss G:  1.1615,Loss D:  0.0554\u001b[0m\n",
      "\u001b[34mEpoch 51, Loss G:  1.3661,Loss D:  0.2001\u001b[0m\n",
      "\u001b[34mEpoch 52, Loss G:  1.3617,Loss D:  0.0802\u001b[0m\n",
      "\u001b[34mEpoch 53, Loss G:  1.1657,Loss D:  0.0879\u001b[0m\n",
      "\u001b[34mEpoch 54, Loss G:  1.3576,Loss D:  0.0908\u001b[0m\n",
      "\u001b[34mEpoch 55, Loss G:  1.3050,Loss D:  0.1006\u001b[0m\n",
      "\u001b[34mEpoch 56, Loss G:  1.5498,Loss D:  0.2140\u001b[0m\n",
      "\u001b[34mEpoch 57, Loss G:  1.3693,Loss D:  0.2388\u001b[0m\n",
      "\u001b[34mEpoch 58, Loss G:  1.5462,Loss D:  0.2794\u001b[0m\n",
      "\u001b[34mEpoch 59, Loss G:  1.4623,Loss D:  0.0397\u001b[0m\n",
      "\u001b[34mEpoch 60, Loss G:  1.3990,Loss D:  0.1365\u001b[0m\n",
      "\u001b[34mEpoch 61, Loss G:  1.4200,Loss D:  0.0904\u001b[0m\n",
      "\u001b[34mEpoch 62, Loss G:  1.3804,Loss D:  0.0789\u001b[0m\n",
      "\u001b[34mEpoch 63, Loss G:  1.2197,Loss D:  0.0843\u001b[0m\n",
      "\u001b[34mEpoch 64, Loss G:  1.3500,Loss D: -0.0489\u001b[0m\n",
      "\u001b[34mEpoch 65, Loss G:  1.3864,Loss D:  0.0972\u001b[0m\n",
      "\u001b[34mEpoch 66, Loss G:  1.1982,Loss D:  0.1259\u001b[0m\n",
      "\u001b[34mEpoch 67, Loss G:  1.1232,Loss D:  0.1676\u001b[0m\n",
      "\u001b[34mEpoch 68, Loss G:  1.3246,Loss D:  0.1523\u001b[0m\n",
      "\u001b[34mEpoch 69, Loss G:  1.1396,Loss D: -0.0107\u001b[0m\n",
      "\u001b[34mEpoch 70, Loss G:  1.0798,Loss D:  0.2037\u001b[0m\n",
      "\u001b[34mEpoch 71, Loss G:  0.8916,Loss D:  0.0693\u001b[0m\n",
      "\u001b[34mEpoch 72, Loss G:  0.8124,Loss D:  0.1723\u001b[0m\n",
      "\u001b[34mEpoch 73, Loss G:  0.6563,Loss D:  0.2426\u001b[0m\n",
      "\u001b[34mEpoch 74, Loss G:  0.7119,Loss D:  0.1103\u001b[0m\n",
      "\u001b[34mEpoch 75, Loss G:  0.7323,Loss D:  0.1570\u001b[0m\n",
      "\u001b[34mEpoch 76, Loss G:  0.6228,Loss D:  0.1458\u001b[0m\n",
      "\u001b[34mEpoch 77, Loss G:  0.6576,Loss D:  0.1461\u001b[0m\n",
      "\u001b[34mEpoch 78, Loss G:  0.6416,Loss D:  0.0348\u001b[0m\n",
      "\u001b[34mEpoch 79, Loss G:  0.5270,Loss D:  0.1760\u001b[0m\n",
      "\u001b[34mEpoch 80, Loss G:  0.4634,Loss D:  0.0414\u001b[0m\n",
      "\u001b[34mEpoch 81, Loss G:  0.4403,Loss D:  0.1731\u001b[0m\n",
      "\u001b[34mEpoch 82, Loss G:  0.4222,Loss D:  0.0225\u001b[0m\n",
      "\u001b[34mEpoch 83, Loss G:  0.3563,Loss D:  0.0525\u001b[0m\n",
      "\u001b[34mEpoch 84, Loss G:  0.5688,Loss D: -0.0910\u001b[0m\n",
      "\u001b[34mEpoch 85, Loss G:  0.4139,Loss D:  0.0000\u001b[0m\n",
      "\u001b[34mEpoch 86, Loss G:  0.4769,Loss D:  0.0123\u001b[0m\n",
      "\u001b[34mEpoch 87, Loss G:  0.5445,Loss D:  0.1061\u001b[0m\n",
      "\u001b[34mEpoch 88, Loss G:  0.3832,Loss D:  0.0574\u001b[0m\n",
      "\u001b[34mEpoch 89, Loss G:  0.3812,Loss D:  0.1212\u001b[0m\n",
      "\u001b[34mEpoch 90, Loss G:  0.3771,Loss D:  0.0250\u001b[0m\n",
      "\u001b[34mEpoch 91, Loss G:  0.3709,Loss D:  0.1491\u001b[0m\n",
      "\u001b[34mEpoch 92, Loss G:  0.5450,Loss D:  0.1439\u001b[0m\n",
      "\u001b[34mEpoch 93, Loss G:  0.4557,Loss D:  0.0294\u001b[0m\n",
      "\u001b[34mEpoch 94, Loss G:  0.5598,Loss D: -0.0080\u001b[0m\n",
      "\u001b[34mEpoch 95, Loss G:  0.6227,Loss D:  0.0337\u001b[0m\n",
      "\n",
      "2023-11-08 10:42:20 Uploading - Uploading generated training model\u001b[34mEpoch 96, Loss G:  0.5896,Loss D: -0.0312\u001b[0m\n",
      "\u001b[34mEpoch 97, Loss G:  0.8394,Loss D:  0.2100\u001b[0m\n",
      "\u001b[34mEpoch 98, Loss G:  0.7291,Loss D: -0.0184\u001b[0m\n",
      "\u001b[34mEpoch 99, Loss G:  0.5890,Loss D: -0.0215\u001b[0m\n",
      "\u001b[34mEpoch 100, Loss G:  0.5314,Loss D:  0.0576\u001b[0m\n",
      "\u001b[34mtraining completed\u001b[0m\n",
      "\n",
      "2023-11-08 10:42:31 Completed - Training job completed\n",
      "Training seconds: 283\n",
      "Billable seconds: 283\n"
     ]
    }
   ],
   "source": [
    "print (\"Now run the training job using algorithm arn %s in region %s\" % (algorithm_arn, sagemaker_session.boto_region_name))\n",
    "algo.fit({'training': training_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "TRANSFORM_WORKDIR = \"data/transform\"\n",
    "filename = os.path.join(TRANSFORM_WORKDIR, \"inference_input.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(filename)\n",
    "data = json.load(f)\n",
    "data['number_of_samples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-1-822940408628/hdts-sagemaker-testing/batch-inference-input-data/inference_input.json\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM_WORKDIR = \"data/transform\"\n",
    "transform_input = sagemaker_session.upload_data(TRANSFORM_WORKDIR, key_prefix=batch_inference_input_prefix) + \"/inference_input.json\"\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model package with name: synth-data-generation-2023-11-08-10-49-11-846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: synth-data-generation-2023-11-08-10-49--2023-11-08-10-49-57-307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: synth-train-marketplace-2023-11-08-10-50-00-153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [10] [INFO] Starting gunicorn 21.2.0\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [10] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [69] [INFO] Booting worker with pid: 69\u001b[0m\n",
      "\n",
      "\u001b[34m169.254.255.130 - - [08/Nov/2023:10:58:32 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Nov/2023:10:58:32 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m10\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [08/Nov/2023:10:58:32 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [08/Nov/2023:10:58:32 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m10\u001b[0m\n",
      "\u001b[32m2023-11-08T10:58:32.669:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Nov/2023:10:58:34 +0000] \"POST /invocations HTTP/1.1\" 200 2445 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [08/Nov/2023:10:58:34 +0000] \"POST /invocations HTTP/1.1\" 200 2445 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [10] [INFO] Starting gunicorn 21.2.0\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [10] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[34m[2023-11-08 10:58:26 +0000] [69] [INFO] Booting worker with pid: 69\u001b[0m\n",
      "\u001b[35mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[35m[2023-11-08 10:58:26 +0000] [10] [INFO] Starting gunicorn 21.2.0\u001b[0m\n",
      "\u001b[35m[2023-11-08 10:58:26 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[35m[2023-11-08 10:58:26 +0000] [10] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2023-11-08 10:58:26 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[35m[2023-11-08 10:58:26 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[35m[2023-11-08 10:58:26 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[35m[2023-11-08 10:58:26 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[35m[2023-11-08 10:58:26 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[35m[2023-11-08 10:58:26 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[35m[2023-11-08 10:58:26 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[35m[2023-11-08 10:58:26 +0000] [69] [INFO] Booting worker with pid: 69\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Nov/2023:10:58:32 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Nov/2023:10:58:32 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m10\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [08/Nov/2023:10:58:32 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [08/Nov/2023:10:58:32 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m10\u001b[0m\n",
      "\u001b[32m2023-11-08T10:58:32.669:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Nov/2023:10:58:34 +0000] \"POST /invocations HTTP/1.1\" 200 2445 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [08/Nov/2023:10:58:34 +0000] \"POST /invocations HTTP/1.1\" 200 2445 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "Batch Transform output saved to s3://sagemaker-us-east-1-822940408628/synth-train-marketplace-2023-11-08-10-50-00-153\n"
     ]
    }
   ],
   "source": [
    "transformer = algo.transformer(1, 'ml.m5.2xlarge')\n",
    "transformer.transform(transform_input, content_type='application/json')\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the Batch Transform Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(transformer.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "file_key = '{}/{}.out'.format(parsed_url.path[1:], \"inference_input.json\")\n",
    "\n",
    "s3_client = sagemaker_session.boto_session.client('s3')\n",
    "\n",
    "response = s3_client.get_object(Bucket = sagemaker_session.default_bucket(), Key = file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucketFolder = transformer.output_path.rsplit('/')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name=\"sagemaker-us-east-1-822940408628\"\n",
    "with open('output.csv', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name, bucketFolder+'/' + \"inference_input.json\" +'.out', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of output df--> 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353.504031</td>\n",
       "      <td>42.815791</td>\n",
       "      <td>Private</td>\n",
       "      <td>525731.107574</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>16.181752</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>173.935159</td>\n",
       "      <td>-35.172755</td>\n",
       "      <td>40.479019</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>636.083117</td>\n",
       "      <td>46.254596</td>\n",
       "      <td>Private</td>\n",
       "      <td>213209.037569</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.863858</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>193.250014</td>\n",
       "      <td>-18.076041</td>\n",
       "      <td>45.312822</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        age workclass         fnlwgt education  education-num  \\\n",
       "0  353.504031  42.815791   Private  525731.107574   7th-8th      16.181752   \n",
       "1  636.083117  46.254596   Private  213209.037569   HS-grad       9.863858   \n",
       "\n",
       "        marital-status      occupation    relationship    race    sex  \\\n",
       "0             Divorced   Other-service       Own-child   White   Male   \n",
       "1   Married-civ-spouse    Adm-clerical   Not-in-family   White   Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0    173.935159    -35.172755       40.479019   United-States   <=50K  \n",
       "1    193.250014    -18.076041       45.312822   United-States   <=50K  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.read_csv('output.csv')\n",
    "print(\"length of output df-->\",len(output_df))\n",
    "output_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name='synth-data-generation'\n",
    "content_type='application/json'\n",
    "\n",
    "real_time_inference_instance_type='ml.m5.2xlarge'\n",
    "batch_transform_inference_instance_type='ml.m5.2xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algorithm ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algorithm_arn ='Put your algorithm ARN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model package with name: synth-train-marketplace-2023-11-08-11-03-48-806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: synth-train-marketplace-2023-11-08-11-03-48-806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint-config with name synth-data-generation\n",
      "INFO:sagemaker:Creating endpoint with name synth-data-generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session,content_type)\n",
    "\n",
    "#create a deployable model from the model package.\n",
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=algorithm_arn,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls=predict_wrapper)\n",
    "\n",
    "#Deploy the model\n",
    "predictor = algo.deploy(1, 'ml.m5.2xlarge',endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name = './data/real-time/input/inferencedata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(filename)\n",
    "data = json.load(f)\n",
    "data['number_of_samples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = './data/real-time/input/inference_input.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file_name = 'output_realtime.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ContentType\": \"text/csv; charset=utf-8\",\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name 'synth-data-generation' \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type 'application/json' \\\n",
    "    --region us-east-1 \\\n",
    "    $output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of output df -- 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>779.024269</td>\n",
       "      <td>55.412423</td>\n",
       "      <td>?</td>\n",
       "      <td>137436.461434</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>11.722291</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>-65.733198</td>\n",
       "      <td>-46.267610</td>\n",
       "      <td>38.671572</td>\n",
       "      <td>Canada</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>662.272870</td>\n",
       "      <td>63.727675</td>\n",
       "      <td>Private</td>\n",
       "      <td>224632.675097</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>12.501260</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>47.837341</td>\n",
       "      <td>-45.202569</td>\n",
       "      <td>40.317680</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        age workclass         fnlwgt      education  \\\n",
       "0  779.024269  55.412423         ?  137436.461434   Some-college   \n",
       "1  662.272870  63.727675   Private  224632.675097        HS-grad   \n",
       "\n",
       "   education-num       marital-status      occupation relationship    race  \\\n",
       "0      11.722291   Married-civ-spouse    Craft-repair      Husband   White   \n",
       "1      12.501260            Separated   Other-service      Husband   Black   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0   Female    -65.733198    -46.267610       38.671572          Canada   <=50K  \n",
       "1     Male     47.837341    -45.202569       40.317680   United-States   <=50K  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.read_csv('output_realtime.csv')\n",
    "print(\"length of output df --\",len(output_df))\n",
    "output_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: synth-data-generation\n",
      "INFO:sagemaker:Deleting endpoint with name: synth-data-generation\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
